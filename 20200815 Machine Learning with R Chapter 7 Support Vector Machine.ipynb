{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glyphs dataset: support vector machine\n",
    "The following exercise is taken from <b> Machine Learning with R</b> by <b> Brett Lantz </b> (Third Edition)\n",
    "\n",
    "The dataset used in the exercise is the <b>printed glyphs</b> dataset. The dataset was orginainally published in a study by <b>Frey and Slate</b> in 1991. The dataset here is downloaded from the textbook's github page. The dataset is also freely available at <b>UCI Machine Learning Repository</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Collecting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters <- read.csv(\"https://raw.githubusercontent.com/PacktPublishing/Machine-Learning-with-R-Third-Edition/master/Chapter07/letterdata.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Exploring and preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t20000 obs. of  17 variables:\n",
      " $ letter: Factor w/ 26 levels \"A\",\"B\",\"C\",\"D\",..: 20 9 4 14 7 19 2 1 10 13 ...\n",
      " $ xbox  : int  2 5 4 7 2 4 4 1 2 11 ...\n",
      " $ ybox  : int  8 12 11 11 1 11 2 1 2 15 ...\n",
      " $ width : int  3 3 6 6 3 5 5 3 4 13 ...\n",
      " $ height: int  5 7 8 6 1 8 4 2 4 9 ...\n",
      " $ onpix : int  1 2 6 3 1 3 4 1 2 7 ...\n",
      " $ xbar  : int  8 10 10 5 8 8 8 8 10 13 ...\n",
      " $ ybar  : int  13 5 6 9 6 8 7 2 6 2 ...\n",
      " $ x2bar : int  0 5 2 4 6 6 6 2 2 6 ...\n",
      " $ y2bar : int  6 4 6 6 6 9 6 2 6 2 ...\n",
      " $ xybar : int  6 13 10 4 6 5 7 8 12 12 ...\n",
      " $ x2ybar: int  10 3 3 4 5 6 6 2 4 1 ...\n",
      " $ xy2bar: int  8 9 7 10 9 6 6 8 8 9 ...\n",
      " $ xedge : int  0 2 3 6 1 0 2 1 1 8 ...\n",
      " $ xedgey: int  8 8 7 10 7 8 8 6 6 1 ...\n",
      " $ yedge : int  0 4 3 2 5 9 7 2 1 1 ...\n",
      " $ yedgex: int  8 10 9 8 10 7 10 7 7 8 ...\n"
     ]
    }
   ],
   "source": [
    "str(letters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 16 statistical attributes were recorded, measuring characteristics such as\n",
    "    - horizontal and vertical dimensions of the glyph\n",
    "    - proportion of black vs white pixels\n",
    "    - average horizontal and vertical position of the pixels\n",
    "- presumably, the concentration of black pixels across the certain areas should provide a way to differentiate the letters\n",
    "- there is no need to convert factors to numeric features (required for SVM) all features are already numeric\n",
    "- while scaling is required, the kernlab package automatically takes care of normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters_train <- letters[1:16000,]\n",
    "letters_test <- letters[16000:20000,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Setting default kernel parameters  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Support Vector Machine object of class \"ksvm\" \n",
       "\n",
       "SV type: C-svc  (classification) \n",
       " parameter : cost C = 1 \n",
       "\n",
       "Linear (vanilla) kernel function. \n",
       "\n",
       "Number of Support Vectors : 7037 \n",
       "\n",
       "Objective Function Value : -14.1746 -20.0072 -23.5628 -6.2009 -7.5524 -32.7694 -49.9786 -18.1824 -62.1111 -32.7284 -16.2209 -32.2837 -28.9777 -51.2195 -13.276 -35.6217 -30.8612 -16.5256 -14.6811 -32.7475 -30.3219 -7.7956 -11.8138 -32.3463 -13.1262 -9.2692 -153.1654 -52.9678 -76.7744 -119.2067 -165.4437 -54.6237 -41.9809 -67.2688 -25.1959 -27.6371 -26.4102 -35.5583 -41.2597 -122.164 -187.9178 -222.0856 -21.4765 -10.3752 -56.3684 -12.2277 -49.4899 -9.3372 -19.2092 -11.1776 -100.2186 -29.1397 -238.0516 -77.1985 -8.3339 -4.5308 -139.8534 -80.8854 -20.3642 -13.0245 -82.5151 -14.5032 -26.7509 -18.5713 -23.9511 -27.3034 -53.2731 -11.4773 -5.12 -13.9504 -4.4982 -3.5755 -8.4914 -40.9716 -49.8182 -190.0269 -43.8594 -44.8667 -45.2596 -13.5561 -17.7664 -87.4105 -107.1056 -37.0245 -30.7133 -112.3218 -32.9619 -27.2971 -35.5836 -17.8586 -5.1391 -43.4094 -7.7843 -16.6785 -58.5103 -159.9936 -49.0782 -37.8426 -32.8002 -74.5249 -133.3423 -11.1638 -5.3575 -12.438 -30.9907 -141.6924 -54.2953 -179.0114 -99.8896 -10.288 -15.1553 -3.7815 -67.6123 -7.696 -88.9304 -47.6448 -94.3718 -70.2733 -71.5057 -21.7854 -12.7657 -7.4383 -23.502 -13.1055 -239.9708 -30.4193 -25.2113 -136.2795 -140.9565 -9.8122 -34.4584 -6.3039 -60.8421 -66.5793 -27.2816 -214.3225 -34.7796 -16.7631 -135.7821 -160.6279 -45.2949 -25.1023 -144.9059 -82.2352 -327.7154 -142.0613 -158.8821 -32.2181 -32.8887 -52.9641 -25.4937 -47.9936 -6.8991 -9.7293 -36.436 -70.3907 -187.7611 -46.9371 -89.8103 -143.4213 -624.3645 -119.2204 -145.4435 -327.7748 -33.3255 -64.0607 -145.4831 -116.5903 -36.2977 -66.3762 -44.8248 -7.5088 -217.9246 -12.9699 -30.504 -2.0369 -6.126 -14.4448 -21.6337 -57.3084 -20.6915 -184.3625 -20.1052 -4.1484 -4.5344 -0.828 -121.4411 -7.9486 -58.5604 -21.4878 -13.5476 -5.646 -15.629 -28.9576 -20.5959 -76.7111 -27.0119 -94.7101 -15.1713 -10.0222 -7.6394 -1.5784 -87.6952 -6.2239 -99.3711 -101.0906 -45.6639 -24.0725 -61.7702 -24.1583 -52.2368 -234.3264 -39.9749 -48.8556 -34.1464 -20.9664 -11.4525 -123.0277 -6.4903 -5.1865 -8.8016 -9.4618 -21.7742 -24.2361 -123.3984 -31.4404 -88.3901 -30.0924 -13.8198 -9.2701 -3.0823 -87.9624 -6.3845 -13.968 -65.0702 -105.523 -13.7403 -13.7625 -50.4223 -2.933 -8.4289 -80.3381 -36.4147 -112.7485 -4.1711 -7.8989 -1.2676 -90.8037 -21.4919 -7.2235 -47.9557 -3.383 -20.433 -64.6138 -45.5781 -56.1309 -6.1345 -18.6307 -2.374 -72.2553 -111.1885 -106.7664 -23.1323 -19.3765 -54.9819 -34.2953 -64.4756 -20.4115 -6.689 -4.378 -59.141 -34.2468 -58.1509 -33.8665 -10.6902 -53.1387 -13.7478 -20.1987 -55.0923 -3.8058 -60.0382 -235.4841 -12.6837 -11.7407 -17.3058 -9.7167 -65.8498 -17.1051 -42.8131 -53.1054 -25.0437 -15.302 -44.0749 -16.9582 -62.9773 -5.204 -5.2963 -86.1704 -3.7209 -6.3445 -1.1264 -122.5771 -23.9041 -355.0145 -31.1013 -32.619 -4.9664 -84.1048 -134.5957 -72.8371 -23.9002 -35.3077 -11.7119 -22.2889 -1.8598 -59.2174 -8.8994 -150.742 -1.8533 -1.9711 -9.9676 -0.5207 -26.9229 -30.429 -5.6289 \n",
       "Training error : 0.130062 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(kernlab)\n",
    "letter_classifier <- ksvm(letter ~ ., data = letters_train, kernel = \"vanilladot\")\n",
    "letter_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Evaluating model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>C</li><li>U</li><li>N</li><li>V</li><li>X</li><li>N</li></ol>\n",
       "\n",
       "<details>\n",
       "\t<summary style=display:list-item;cursor:pointer>\n",
       "\t\t<strong>Levels</strong>:\n",
       "\t</summary>\n",
       "\t<style>\n",
       "\t.list-inline {list-style: none; margin:0; padding: 0}\n",
       "\t.list-inline>li {display: inline-block}\n",
       "\t.list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "\t</style>\n",
       "\t<ol class=list-inline><li>'A'</li><li>'B'</li><li>'C'</li><li>'D'</li><li>'E'</li><li>'F'</li><li>'G'</li><li>'H'</li><li>'I'</li><li>'J'</li><li>'K'</li><li>'L'</li><li>'M'</li><li>'N'</li><li>'O'</li><li>'P'</li><li>'Q'</li><li>'R'</li><li>'S'</li><li>'T'</li><li>'U'</li><li>'V'</li><li>'W'</li><li>'X'</li><li>'Y'</li><li>'Z'</li></ol>\n",
       "</details>"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item C\n",
       "\\item U\n",
       "\\item N\n",
       "\\item V\n",
       "\\item X\n",
       "\\item N\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\emph{Levels}: \\begin{enumerate*}\n",
       "\\item 'A'\n",
       "\\item 'B'\n",
       "\\item 'C'\n",
       "\\item 'D'\n",
       "\\item 'E'\n",
       "\\item 'F'\n",
       "\\item 'G'\n",
       "\\item 'H'\n",
       "\\item 'I'\n",
       "\\item 'J'\n",
       "\\item 'K'\n",
       "\\item 'L'\n",
       "\\item 'M'\n",
       "\\item 'N'\n",
       "\\item 'O'\n",
       "\\item 'P'\n",
       "\\item 'Q'\n",
       "\\item 'R'\n",
       "\\item 'S'\n",
       "\\item 'T'\n",
       "\\item 'U'\n",
       "\\item 'V'\n",
       "\\item 'W'\n",
       "\\item 'X'\n",
       "\\item 'Y'\n",
       "\\item 'Z'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. C\n",
       "2. U\n",
       "3. N\n",
       "4. V\n",
       "5. X\n",
       "6. N\n",
       "\n",
       "\n",
       "\n",
       "**Levels**: 1. 'A'\n",
       "2. 'B'\n",
       "3. 'C'\n",
       "4. 'D'\n",
       "5. 'E'\n",
       "6. 'F'\n",
       "7. 'G'\n",
       "8. 'H'\n",
       "9. 'I'\n",
       "10. 'J'\n",
       "11. 'K'\n",
       "12. 'L'\n",
       "13. 'M'\n",
       "14. 'N'\n",
       "15. 'O'\n",
       "16. 'P'\n",
       "17. 'Q'\n",
       "18. 'R'\n",
       "19. 'S'\n",
       "20. 'T'\n",
       "21. 'U'\n",
       "22. 'V'\n",
       "23. 'W'\n",
       "24. 'X'\n",
       "25. 'Y'\n",
       "26. 'Z'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] C U N V X N\n",
       "Levels: A B C D E F G H I J K L M N O P Q R S T U V W X Y Z"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "                  \n",
       "letter_predictions   A   B   C   D   E   F   G   H   I   J   K   L   M   N   O\n",
       "                 A 144   0   0   0   0   0   0   0   0   1   0   0   1   2   2\n",
       "                 B   0 121   0   5   2   0   1   2   0   0   1   0   1   0   0\n",
       "                 C   0   0 121   0   4   0  10   2   2   0   1   3   0   0   2\n",
       "                 D   2   2   0 156   0   1   3  10   4   3   4   3   0   5   5\n",
       "                 E   0   0   5   0 127   3   1   1   0   0   3   4   0   0   0\n",
       "                 F   0   0   0   0   0 138   2   2   6   0   0   0   0   0   0\n",
       "                 G   1   1   2   1   9   2 123   2   0   0   1   2   1   0   1\n",
       "                 H   0   0   0   1   0   1   0 102   0   2   3   2   3   4  20\n",
       "                 I   0   1   0   0   0   1   0   0 141   8   0   0   0   0   0\n",
       "                 J   0   1   0   0   0   1   0   2   5 128   0   0   0   0   1\n",
       "                 K   1   1   9   0   0   0   2   5   0   0 118   0   0   2   0\n",
       "                 L   0   0   0   0   2   0   1   1   0   0   0 133   0   0   0\n",
       "                 M   0   0   1   1   0   0   1   1   0   0   0   0 135   4   0\n",
       "                 N   0   0   0   0   0   1   0   1   0   0   0   0   0 145   0\n",
       "                 O   1   0   2   1   0   0   1   2   0   1   0   0   0   1  99\n",
       "                 P   0   0   0   1   0   2   1   0   0   0   0   0   0   0   2\n",
       "                 Q   0   0   0   0   0   0   8   2   0   0   0   3   0   0   3\n",
       "                 R   0   7   0   0   1   0   3   8   0   0  13   0   0   1   1\n",
       "                 S   1   1   0   0   1   0   3   0   1   1   0   1   0   0   0\n",
       "                 T   0   0   0   0   3   2   0   0   0   0   1   0   0   0   0\n",
       "                 U   1   0   3   1   0   0   0   2   0   0   0   0   0   0   1\n",
       "                 V   0   0   0   0   0   1   3   4   0   0   0   0   1   2   1\n",
       "                 W   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0\n",
       "                 X   0   1   0   0   2   0   0   1   3   0   1   6   0   0   1\n",
       "                 Y   3   0   0   0   0   0   0   1   0   0   0   0   0   0   0\n",
       "                 Z   2   0   0   0   1   0   0   0   3   4   0   0   0   0   0\n",
       "                  \n",
       "letter_predictions   P   Q   R   S   T   U   V   W   X   Y   Z\n",
       "                 A   0   5   0   1   1   1   0   1   0   0   1\n",
       "                 B   2   2   3   5   0   0   2   0   1   0   0\n",
       "                 C   0   0   0   0   0   0   0   0   0   0   0\n",
       "                 D   3   1   4   0   0   0   0   0   3   3   1\n",
       "                 E   0   2   0  10   0   0   0   0   2   0   3\n",
       "                 F  16   0   0   3   0   0   1   0   1   2   0\n",
       "                 G   2   8   2   4   3   0   0   0   1   0   0\n",
       "                 H   0   2   3   0   3   0   2   0   0   1   0\n",
       "                 I   1   0   0   3   0   0   0   0   5   1   1\n",
       "                 J   1   3   0   2   0   0   0   0   1   0   6\n",
       "                 K   1   0   7   0   1   3   0   0   5   0   0\n",
       "                 L   0   1   0   5   0   0   0   0   0   0   1\n",
       "                 M   0   0   0   0   0   3   0   8   0   0   0\n",
       "                 N   0   0   3   0   0   1   0   2   0   0   0\n",
       "                 O   3   3   0   0   0   3   0   0   0   0   0\n",
       "                 P 130   0   0   0   0   0   0   0   0   1   0\n",
       "                 Q   1 124   0   5   0   0   0   0   0   2   0\n",
       "                 R   1   0 138   0   1   0   1   0   0   0   0\n",
       "                 S   0  14   0 101   3   0   0   0   2   0  10\n",
       "                 T   0   0   0   3 133   1   0   0   0   2   2\n",
       "                 U   0   0   0   0   0 152   0   0   1   1   0\n",
       "                 V   0   3   1   0   0   0 126   1   0   4   0\n",
       "                 W   0   0   0   0   0   4   4 127   0   0   0\n",
       "                 X   0   0   0   1   0   0   0   0 137   1   1\n",
       "                 Y   7   0   0   0   3   0   0   0   0 127   0\n",
       "                 Z   0   0   0  18   3   0   0   0   0   0 132"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "letter_predictions <- predict(letters_classifier, letters_test)\n",
    "head(letter_predictions)\n",
    "table(letter_predictions, letters_test$letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "agreement\n",
       "FALSE  TRUE \n",
       "  643  3358 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "agreement <- letter_predictions == letters_test$letter\n",
    "table(agreement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "agreement\n",
       "    FALSE      TRUE \n",
       "0.1607098 0.8392902 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prop.table(table(agreement))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Improving model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing the SVM kernel function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "agreement_rbf\n",
       "FALSE  TRUE \n",
       "  277  3724 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "agreement_rbf\n",
       "     FALSE       TRUE \n",
       "0.06923269 0.93076731 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "letters_classifier_rbf <- ksvm(letter ~ ., data = letters_train, kernel = \"rbfdot\")\n",
    "letter_predictions_rbf <- predict(letters_classifier_rbf, letters_test)\n",
    "agreement_rbf <- letter_predictions_rbf == letters_test$letter\n",
    "\n",
    "table(agreement_rbf)\n",
    "prop.table(table(agreement_rbf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying the best SVM cost parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAMFBMVEUAAABNTU1oaGh8fHyM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\nBBASBBASBBASBBASBBASBBASBBASBPgPct4Mr3t1RYAAAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the cost function \n",
    "\n",
    "cost_values <- c(1, seq(5, 40, 5))\n",
    "\n",
    "accuracy_values <- sapply(cost_values, function(x){\n",
    "    set.seed(12345)\n",
    "    m <- ksvm(letter ~ ., data = letters_train, kernel = \"rbfdot\",\n",
    "             C = x)\n",
    "    pred <- predict(m, letters_test)\n",
    "    agree <- ifelse(pred == letters_test$letter, 1, 0)\n",
    "    accuracy <- sum(agree) / nrow(letters_test)\n",
    "    return (accuracy)\n",
    "})\n",
    "\n",
    "plot(cost_values, accuracy_values, type = \"b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- a C = 1 value clearly performs the worst\n",
    "- C = 10 appears to be the most promising cost value, with roughly 97% accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
